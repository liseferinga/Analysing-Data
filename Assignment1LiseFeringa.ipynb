{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2c8f03-538f-4726-994f-6422404072ef",
   "metadata": {},
   "source": [
    "# **Analysing Data - Assignment 1 - Lise Feringa**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b20576-bc3f-49f9-bc3e-8b34e7bd7815",
   "metadata": {},
   "source": [
    "# Part 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ae913-3e04-42f1-a485-c2a11740217b",
   "metadata": {},
   "source": [
    "For this exercise, I will analyze texts in a dataset by **splitting sentences and applying word tokenization**. The results will be reported as statistics of word frequency (per story and in total) in a **python dictionary** and plotted in the form of a **histogram**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0176678-fcd6-4cdd-b450-901ca55ae4ae",
   "metadata": {},
   "source": [
    "> Note: the dataset used for this assignment contains of fanfiction stories based on the British sci-fi TV series _Doctor Who_. The stories revolve around 'what if' scenarios that make up alternate interpretations of fans of canon events in the show. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fae51-a2f3-493a-8bf5-f3f6ea45525f",
   "metadata": {},
   "source": [
    "### Importing and Downloading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af3a05-ca93-4d69-bef6-54e007e82785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f51c3-0eb9-404c-9120-738ac57d997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebabf76-cddd-48a2-a20d-fc71b3e85838",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'{str(i).zfill(2)}.txt' for i in range(1, 6)]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences_dict = {}\n",
    "words_dict = {}\n",
    "freq_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d2a3b-b426-47e4-87f2-540f99bc314f",
   "metadata": {},
   "source": [
    "### Function of processing each story **(cleaned + lowercased)** and getting the top 25 most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7c599-9914-4dc6-b770-e40b3191b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()        \n",
    "\n",
    "    story_name = file\n",
    "    \n",
    "    # Sentence splitting\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences_dict[story_name] = sentences\n",
    "\n",
    "    # Word tokenization\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [w for w in words if w.isalpha() and w not in stop_words]\n",
    "    words_dict[story_name] = words\n",
    "\n",
    "    # Word frequency\n",
    "    freq_dict[story_name] = Counter(words)\n",
    "\n",
    "    # Total frequency across all stories\n",
    "total_freq = sum(freq_dict.values(), Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7886a-6bf0-47d6-bbb6-2cfe4748a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25 per story \n",
    "top25_per_story = {\n",
    "    story: dict(freq.most_common(25))\n",
    "    for story, freq in freq_dict.items()\n",
    "}\n",
    "\n",
    "# Top 25 in total \n",
    "top25_total = dict(total_freq.most_common(25))\n",
    "\n",
    "# Plot results \n",
    "def plot_top_words(counter, title):\n",
    "    top_words = counter.most_common(25)\n",
    "    words, counts = zip(*top_words)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(words, counts, color=\"lightpink\")\n",
    "    plt.gca().invert_yaxis() \n",
    "    \n",
    "    plt.xlabel(\"Frequency\", fontsize=12)\n",
    "    plt.ylabel(\"Words\", fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7f63a-f382-4d1f-bdbc-a1149327819b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0d1bc-40fe-4c2a-827c-c7c075e8440b",
   "metadata": {},
   "source": [
    "# Part 1.1 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d9d07-14fe-4b85-b93a-2a09f9dffd65",
   "metadata": {},
   "source": [
    "### **Dictionary 1** : top 25 words per story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a23ca-a259-41a0-b5a9-4dab1a36d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 25 Words Per Story:\")\n",
    "print(top25_per_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa047b-9832-401b-bc98-4d2de5bf4de4",
   "metadata": {},
   "source": [
    "### **Dictionary 2** : top 25 words across all stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069a96d-c22d-4916-ad8c-8eb101fd4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 25 Words Across all Stories:\")\n",
    "print(top25_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478987a0-0bf9-4637-b282-8081a57ae6ad",
   "metadata": {},
   "source": [
    "### **Histogram 1** : Top 25 Words Per Story "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ece52-7760-46cf-acd5-6e776ec4690d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for story, freq in freq_dict.items():\n",
    "    plot_top_words(freq, f\"Top 25 Words in {story}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a784ee-4b3b-43bb-a307-9d11a7b59e5a",
   "metadata": {},
   "source": [
    "### **Histogram 2** : Top 25 Words Across All Stories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96829770-7185-4c27-b88a-b66cd8d61580",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(total_freq, \"Top 25 Words Across All Stories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c32f9-19ae-42a3-a5d7-804879d598f6",
   "metadata": {},
   "source": [
    "# Part 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e35dad-74c7-400d-9f8b-2f159ec941b6",
   "metadata": {},
   "source": [
    "For the second exercise, I will perform **stemming** on the texts using Porter and Lancaster stemmer. I will re-create the statistics and the plot from exercise 1 with the stemmed texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e7ce2-84e5-4953-822d-90c1638af73f",
   "metadata": {},
   "source": [
    "### Import Stemming methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e05e37-7c70-4012-8939-5bf00cf5e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceb85d-2d67-452b-93ad-626d7618f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_porter = {}\n",
    "freq_lancaster = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948cc20-edfe-4a01-9d97-9f737888d030",
   "metadata": {},
   "source": [
    "### Applying stemming per story and in total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc144b87-d3fa-4dd6-a535-b847631d561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name, words in words_dict.items():\n",
    "    # Porter stemming\n",
    "    porter_words = [porter.stem(w) for w in words]\n",
    "    freq_porter[story_name] = Counter(porter_words)\n",
    "    \n",
    "    # Lancaster stemming\n",
    "    lancaster_words = [lancaster.stem(w) for w in words]\n",
    "    freq_lancaster[story_name] = Counter(lancaster_words)\n",
    "\n",
    "total_porter = sum(freq_porter.values(), Counter())\n",
    "total_lancaster = sum(freq_lancaster.values(), Counter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96e71b-1ae6-4322-8576-15d0e06d04dc",
   "metadata": {},
   "source": [
    "### Functions to plot and make dictionaries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9868a-3659-4658-bdf6-146f675606c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(counter, title):\n",
    "    top_words = counter.most_common(25)\n",
    "    words, counts = zip(*top_words)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.bar(words, counts, color='lightpink')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "total_unstemmed = sum(freq_dict.values(), Counter())\n",
    "total_porter = sum(freq_porter.values(), Counter())\n",
    "total_lancaster = sum(freq_lancaster.values(), Counter())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc331d-fff6-448c-8de6-0ce983cefd94",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3589e771-c0ab-41ba-92de-a716ff2d1e33",
   "metadata": {},
   "source": [
    "# Part 1.2 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f235f-5e03-430d-8b9c-0cb293b91a52",
   "metadata": {},
   "source": [
    "### **Dictonary 1, 2, 3** : Top 25 Words per method, per story "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b79b33-542a-46e6-9549-a4dc431ef5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in words_dict.keys():\n",
    "    print(f\"\\n--- {story_name} ---\")\n",
    "    print(\"Top 25 unstemmed:\", freq_dict[story_name].most_common(25))\n",
    "    print(\"Top 25 Porter-stemmed:\", freq_porter[story_name].most_common(25))\n",
    "    print(\"Top 25 Lancaster-stemmed:\", freq_lancaster[story_name].most_common(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d8c95-c0bd-4594-a3f8-bd5868db811a",
   "metadata": {},
   "source": [
    "### **Dictionary 4, 5, 6** : Top 25 Words per method, in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2dc02-de25-4d03-ab4c-3138b8718e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 25 Total Words (Unstemmed):\")\n",
    "print(total_unstemmed.most_common(25))\n",
    "\n",
    "print(\"\\nTop 25 Total Words (Porter Stemmed):\")\n",
    "print(total_porter.most_common(25))\n",
    "\n",
    "print(\"\\nTop 25 Total Words (Lancaster Stemmed):\")\n",
    "print(total_lancaster.most_common(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7d95d-a4a7-4b9a-9e4a-b8ccee3a38a8",
   "metadata": {},
   "source": [
    "### **Histogram 1, 2, 3** : Top 25 Words per method, per story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba6579-d8f6-494b-84fe-5ee87ec3735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(freq_dict[story_name], f\"Top 25 unstemmed words in {story_name}\")\n",
    "plot_top_words(freq_porter[story_name], f\"Top 25 Porter-stemmed words in {story_name}\")\n",
    "plot_top_words(freq_lancaster[story_name], f\"Top 25 Lancaster-stemmed words in {story_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5e101-ef6f-4e64-91e3-b0e2c24d1108",
   "metadata": {},
   "source": [
    "### **Histogram 4, 5, 6** : Top 25 Words per method, in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e1a58-dd8b-47f5-9e02-21fb350f3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_words(total_freq, \"Top 25 unstemmed words in Total\")\n",
    "plot_top_words(total_porter, \"Top 25 Porter-stemmed words in Total\")\n",
    "plot_top_words(total_lancaster, \"Top 25 Lancaster-stemmed words in Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9c6c0-564e-43c2-ab6c-1b5bdd37dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unstemmed vocab size:\", len(total_freq))\n",
    "print(\"Porter vocab size:\", len(total_porter))\n",
    "print(\"Lancaster vocab size:\", len(total_lancaster))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b599c-56d5-4ace-a5b8-03ddfa147fa6",
   "metadata": {},
   "source": [
    "After stemming, the total number of unique word forms decreases because morphological variants are merged into their common root (for example: running, runs, and ran are all reduced to run). The _Porter_ stemmer produces relatively readable stems (words that still resemble actual words) and maintains clearer distinctions between different terms. The _Lancaster_ stemmer, on the other hand, is more 'aggressive' and produces shorter and  less interpretable stems. Also, as a result, Lancaster generally reduces the vocabulary size more than Porter. This may distort semantic distinctions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2042b-de71-4335-98f5-41b457ffe13d",
   "metadata": {},
   "source": [
    "# Part 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2eb87d-a377-4df4-8282-6debf3c06848",
   "metadata": {},
   "source": [
    "For the this exercise, I will use three translations of _Tom Sawyer_ by Mark Twain. First, I will clean the document. Then, I will use SpaCy to derrive the **POS-tags** of the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5fb9e-6e0a-4199-a5cc-ffc04348fd35",
   "metadata": {},
   "source": [
    "> _Tom Sawyer_ by Mark Twain is a novel that follows a mischievous and adventurous boy, as he navigates childhood adventures and moral lessons. The dataset used in this exercise contains the English, the Dutch and the German translation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761f12c-512d-4360-8f9b-66e87a6f3f39",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6fad4-5e97-404d-9c80-2287d9d65860",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ea11e-9a38-4e0e-8732-21679e7e4ac7",
   "metadata": {},
   "source": [
    "### Cleaning Funtion (Removing Preamble, TOC and Licence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4dcbd2-0de1-498c-b36f-a85a1286cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "files = [\"pg74.txt\", \"pg18381.txt\", \"pg30165.txt\"]\n",
    "\n",
    "languages = {\n",
    "    \"pg74.txt\": \"english\",\n",
    "    \"pg18381.txt\": \"dutch\",\n",
    "    \"pg30165.txt\": \"german\"\n",
    "}\n",
    "\n",
    "def clean_gutenberg_full(text, language=\"english\"):\n",
    "    text = text.replace('\\r', '\\n')\n",
    "    \n",
    "    start_marker = \"*** START OF\"\n",
    "    end_marker = \"*** END OF\"\n",
    "    \n",
    "    start_idx = text.find(start_marker)\n",
    "    if start_idx != -1:\n",
    "        text = text[start_idx:]\n",
    "        text = text.split(\"\\n\", 1)[-1]\n",
    "    \n",
    "    end_idx = text.find(end_marker)\n",
    "    if end_idx != -1:\n",
    "        text = text[:end_idx]\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    chapter_patterns = {\n",
    "        \"english\": r'CHAPTER I[^\\n]*\\n\\n',   \n",
    "        \"dutch\": r'HOOFDSTUK I[^\\n]*\\n\\n',\n",
    "        \"german\": r'Erstes Kapitel[^\\n]*\\n\\n'\n",
    "    }\n",
    "    \n",
    "    pattern = chapter_patterns.get(language, r'CHAPTER I[^\\n]*\\n\\n')\n",
    "    \n",
    "    # The function sees all CHAPTER I occurrences, take the last to skip the TOC \n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    if matches:\n",
    "        start_idx = matches[-1].end()\n",
    "        text = text[start_idx:]\n",
    "    \n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_texts = {}\n",
    "for file in files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_text = f.read()\n",
    "        lang = languages[file]\n",
    "        clean_texts[file] = clean_gutenberg_full(raw_text, language=lang)\n",
    "        print(f\"{file} cleaned. Length: {len(clean_texts[file])} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc8fa7-392c-4004-af23-5ab5f522b222",
   "metadata": {},
   "source": [
    "### _Preview_: first 1000 characters of each cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf2828-54f4-4cc8-b64e-8a475469c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, text in clean_texts.items():\n",
    "    print(f\"\\n--- {file} ---\\n{text[:1000]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e75a3-12f2-4ced-8261-288fc22a7c27",
   "metadata": {},
   "source": [
    "### POS-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4b0d8-98bf-48a6-a100-21d45db66015",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts = {}\n",
    "\n",
    "for file, text in texts.items():\n",
    "    print(f\"\\nProcessing {file} ...\")\n",
    "    doc = nlp(text)\n",
    "    # Count POS tags\n",
    "    counts = Counter([token.pos_ for token in doc])\n",
    "    pos_counts[file] = counts\n",
    "    print(f\"Top 10 POS tags in {file}:\", counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e82c1c-1632-4002-9337-9430428d8825",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d5d8d-b704-4fa3-a98b-19245bc0bd24",
   "metadata": {},
   "source": [
    "# Part 1.3 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe43c63-2658-4284-ad04-6f7cd98334a0",
   "metadata": {},
   "source": [
    "## **POS tags**:\n",
    " - ADJ:\tAdjective <br>\n",
    " - ADP:\tAdposition (prepositions and postpositions) <br>\n",
    " - ADV:\tAdverb <br>\n",
    " - AUX:\tAuxiliary verb <br>\n",
    " - CONJ/CCONJ:\tCoordinating conjunction <br>\n",
    " - DET:\tDeterminer <br>\n",
    " - INTJ:\tInterjection <br>\n",
    " - NOUN:\tNoun <br>\n",
    " - NUM:\tNumeral <br>\n",
    " - PART:\tParticle <br>\n",
    " - PRON:\tPronoun <br>\n",
    " - PROPN:\tProper noun <br>\n",
    " - PUNCT:\tPunctuation <br>\n",
    " - SCONJ:\tSubordinating conjunction <br>\n",
    " - SYM:\tSymbol <br>\n",
    " - VERB:\tVerb <br>\n",
    " - X:\tOther/unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53055de2-681e-4aff-af5a-d59c44963f06",
   "metadata": {},
   "source": [
    "### **Histogram 1, 2, 3** : Top POS tags per text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146eb397-d7c3-4071-b8c7-caf3c5c718b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for file, counts in pos_counts.items():\n",
    "    labels, values = zip(*counts.most_common(10))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(labels, values, color='lightpink')\n",
    "    plt.title(f\"Top POS tags in {file}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966019fc-d243-4b1d-9710-ad687ca4cf4d",
   "metadata": {},
   "source": [
    "### **Bar Chart 1** : Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a366df-7c6c-4f27-a9ae-eaf08b104260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "file_lang = {\n",
    "    \"pg74.txt\": \"English\",\n",
    "    \"pg18381.txt\": \"Dutch\",\n",
    "    \"pg30165.txt\": \"German\"\n",
    "}\n",
    "\n",
    "all_tags = set()\n",
    "for counts in pos_counts.values():\n",
    "    all_tags.update(counts.keys())\n",
    "all_tags = sorted(all_tags)\n",
    "\n",
    "df = pd.DataFrame({file_lang[file]: [pos_counts[file].get(tag, 0) for tag in all_tags]\n",
    "                   for file in pos_counts}, index=all_tags)\n",
    "\n",
    "x = np.arange(len(all_tags))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "ax.bar(x - width, df['English'], width, label='English', color='lightpink')\n",
    "ax.bar(x, df['Dutch'], width, label='Dutch', color='lightyellow')\n",
    "ax.bar(x + width, df['German'], width, label='German', color='skyblue')\n",
    "\n",
    "ax.set_xlabel('POS Tags', fontsize=12)\n",
    "ax.set_ylabel('Counts', fontsize=12)\n",
    "ax.set_title('POS Tag Comparison Across English, Dutch, and German', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_tags, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861e87d-f7ad-410b-8e3c-35c69c12744a",
   "metadata": {},
   "source": [
    "# Part 1.3 - Conclusion\n",
    "The Dutch and German texts show higher proper noun (PROPN) counts, suggesting more explicit naming of characters instead of using pronouns (that is much higher in the English translation). Instead of naming '_Tom_', the English language refers to him as '_he_'. This is a stylistic choice the translator made. The English translation also uses more verbs. Maybe the English text is more action-orientated than decriptive. Further, the English text contains more combines conjuctions. This suggests that the English translator tends to link clauses and phrases more explicitly with words like _and_, _but_, _or_, making the narrative flow in longer, connected sentences. These results can be explained by stylistic differences, but also account for linguistic differences: for example, in English, there are noticeably more DET tokens, which reflects English's tendency for explicit noun marking. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877bf67-d179-4729-b575-09c7a53790fd",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ee9ba-0480-4384-ba1e-8a2ad0076fe7",
   "metadata": {},
   "source": [
    "In the final part of this assignment, I will investigate 5 sentences from the texts in the '_Docter Who_' fanfiction (1 sentence per story). I will use **Named Entity Recognition** to automatically annotate these sentences and compare these to manual annotation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e3dd3-ba09-4563-b3ce-e2d82fc4f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Dataset consisting of 1 sentence per story \n",
    "sentences = [\n",
    "    \"Missy was sitting on a chair in a house, maps and papers spread around, normally her planning was mental, but River had suggested a physical map to refer to and it was helpful.\",\n",
    "    \"She sat in her bed, thinking over how she got here, her husband, a man, and occasionally women, she loved, who also made her want to slap him, he hadn’t known who she was, she thought back to something she once told her father, well, the Doctor not knowing who she was had killed her.\",\n",
    "    \"He'd begged her, pleaded with Rose to just give up the power of the vortex, and when she'd dismissed him, when she'd told him she'd done it for him, because she wanted him safe...\",\n",
    "    \"Rose brought a new joy into The Doctor’s life that he never thought he would feel again.\",\n",
    "    \"The Doctor closed her eyes and let out an exasperated sigh, hands crossed over her chest in a defensive manner.\"\n",
    "]\n",
    "\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    doc = nlp(sent)\n",
    "    print(f\"\\nSentence {i}: {sent}\\nNamed Entities:\")\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(f\"  {ent.text} ({ent.label_})\")\n",
    "    else:\n",
    "        print(\"  No entities detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2266d-ba0b-4f7a-b2a6-69c93ef45a10",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55ff03-07a1-47fe-a457-13273bf14c04",
   "metadata": {},
   "source": [
    "# Part 2 - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe90a9-b43c-411b-a24b-618bf5501b79",
   "metadata": {},
   "source": [
    "My own (non-automatic) annotation has the following results: <br> \n",
    "Missy (**PERSON**), River (**PERSON**)(_it is interesting that the NER sees River as a LOC_) <br> \n",
    "Doctor (**PERSON**) <br>\n",
    "Rose (**PERSON**) (_this the only one corresponding with the automatic recognition_) <br>\n",
    "Rose (**PERSON**), Doctor (**PERSON**) <br>\n",
    "Doctor (**PERSON**) <br>\n",
    "\n",
    "So from this (very small) dataset, we could conclude that non-automatic annotation is better. However, this conclusion is based on only 5 sentences, and from the 5, 1 was correct. I think that SpaCy’s default NER model can capture clear, standard character names, but struggles with titles, honorifics, or multi-word character names (e.g., “_The Doctor_”) and names that depend on context. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
